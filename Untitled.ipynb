{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('data/2017firsthalf.txt', sep=\"\\t\", encoding='latin-1', dtype={'componentText': str})\n",
    "data2 = pd.read_csv('data/2017secondhalf.txt', sep=\"\\t\", encoding='latin-1', dtype={'componentText': str})\n",
    "data3 = pd.read_csv('data/2018.txt', sep=\"\\t\", encoding='latin-1', dtype={'componentText': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transcript_train = pd.concat([data1, data2, data3])\n",
    "transcript_train = data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>objectId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>1.461750e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>3.430898e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.610479e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.871100e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>9.103100e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>1.808710e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>3.053040e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.418857e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           objectId\n",
       "count  1.461750e+05\n",
       "mean   3.430898e+06\n",
       "std    1.610479e+07\n",
       "min    1.871100e+04\n",
       "25%    9.103100e+04\n",
       "50%    1.808710e+05\n",
       "75%    3.053040e+05\n",
       "max    1.418857e+08"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 146175 entries, 0 to 146174\n",
      "Data columns (total 3 columns):\n",
      "objectId                     146175 non-null int64\n",
      "transcriptcreationdateUTC    146175 non-null object\n",
      "componentText                146175 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "transcript_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>objectId</th>\n",
       "      <th>transcriptcreationdateUTC</th>\n",
       "      <th>componentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>106335</td>\n",
       "      <td>2017-01-04 15:40:41.000</td>\n",
       "      <td>Good morning. My name is Kalia and I will be y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>106335</td>\n",
       "      <td>2017-01-04 15:40:41.000</td>\n",
       "      <td>Thank you, Kalia, and welcome, everyone, to Fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>106335</td>\n",
       "      <td>2017-01-04 15:40:41.000</td>\n",
       "      <td>Thank you, Erich, and Happy New Year to everyo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>106335</td>\n",
       "      <td>2017-01-04 15:40:41.000</td>\n",
       "      <td>Great. Thanks, Mark. And welcome, everyone, to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>106335</td>\n",
       "      <td>2017-01-04 15:40:41.000</td>\n",
       "      <td>Thank you, Emily. And I'm just going to take a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   objectId transcriptcreationdateUTC  \\\n",
       "0    106335   2017-01-04 15:40:41.000   \n",
       "1    106335   2017-01-04 15:40:41.000   \n",
       "2    106335   2017-01-04 15:40:41.000   \n",
       "3    106335   2017-01-04 15:40:41.000   \n",
       "4    106335   2017-01-04 15:40:41.000   \n",
       "\n",
       "                                       componentText  \n",
       "0  Good morning. My name is Kalia and I will be y...  \n",
       "1  Thank you, Kalia, and welcome, everyone, to Fo...  \n",
       "2  Thank you, Erich, and Happy New Year to everyo...  \n",
       "3  Great. Thanks, Mark. And welcome, everyone, to...  \n",
       "4  Thank you, Emily. And I'm just going to take a...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_train['transcriptcreationdateUTC'] = pd.to_datetime(transcript_train['transcriptcreationdateUTC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 146175 entries, 0 to 146174\n",
      "Data columns (total 3 columns):\n",
      "objectId                     146175 non-null int64\n",
      "transcriptcreationdateUTC    146175 non-null datetime64[ns]\n",
      "componentText                146175 non-null object\n",
      "dtypes: datetime64[ns](1), int64(1), object(1)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "transcript_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transcript_train['componentText'] = transcript_train['componentText'].to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3h 23min 17s, sys: 1min 22s, total: 3h 24min 40s\n",
      "Wall time: 43min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "transcript_train['parsed_componentText'] = transcript_train.iloc[:,2].apply(lambda x: nlp(x))\n",
    "#test = nlp(transcript_train.iloc[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Good morning. My name is Kalia and I will be your conference operator today. At this time, I would like to welcome everyone to the Ford Monthly Sales Conference Call. [Operator Instructions] Thank you.   I would now like to turn the call over to our host, Erich Merkle, U.S. sales analyst. Please go ahead."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_train.iloc[:,3][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatization and removing stop words\n",
    "transcript_train['parsed_componentText_lemma'] = transcript_train.iloc[:,3].apply(lambda text: \n",
    "                                          \" \".join(token.lemma_ for token in text if not token.is_stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good morning . Kalia conference operator today . time , like welcome Ford Monthly Sales conference . [ Operator Instructions ] thank .    like turn host , Erich Merkle , U.S. sale analyst . ahead .'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_train.iloc[:,4][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding customized stop words\n",
    "# # New stop words list \n",
    "# customize_stop_words = [\n",
    "#     'attach'\n",
    "# ]\n",
    "\n",
    "# # Mark them as stop words\n",
    "# for w in customize_stop_words:\n",
    "#     nlp.vocab[w].is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_train['month'] = transcript_train['transcriptcreationdateUTC'].apply(lambda x: x.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_train1=transcript_train.groupby(['objectId','month'])['parsed_componentText_lemma'].apply(' '.join).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>objectId</th>\n",
       "      <th>month</th>\n",
       "      <th>parsed_componentText_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>18711</td>\n",
       "      <td>2</td>\n",
       "      <td>good day , lady gentleman , welcome Allstate F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>18711</td>\n",
       "      <td>5</td>\n",
       "      <td>good day , lady gentleman , welcome Allstate Q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>18749</td>\n",
       "      <td>2</td>\n",
       "      <td>thank stand . good day , , welcome Amazon.com ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>18749</td>\n",
       "      <td>4</td>\n",
       "      <td>thank stand . good day , , welcome Amazon.com ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>19049</td>\n",
       "      <td>1</td>\n",
       "      <td>good day , , welcome Bank America Earnings Ann...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>418</td>\n",
       "      <td>141885706</td>\n",
       "      <td>1</td>\n",
       "      <td>good morning , everybody . Chri Schott , pharm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>419</td>\n",
       "      <td>141885706</td>\n",
       "      <td>3</td>\n",
       "      <td>okay . good morning , welcome second day Barcl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>141885706</td>\n",
       "      <td>4</td>\n",
       "      <td>good morning , thank stand . welcome AbbVie Qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>421</td>\n",
       "      <td>141885706</td>\n",
       "      <td>5</td>\n",
       "      <td>good morning , . welcome . go ahead start . Gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>422</td>\n",
       "      <td>141885706</td>\n",
       "      <td>6</td>\n",
       "      <td>hello , welcome , everybody . Jeff Holford , c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>423 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      objectId  month                         parsed_componentText_lemma\n",
       "0        18711      2  good day , lady gentleman , welcome Allstate F...\n",
       "1        18711      5  good day , lady gentleman , welcome Allstate Q...\n",
       "2        18749      2  thank stand . good day , , welcome Amazon.com ...\n",
       "3        18749      4  thank stand . good day , , welcome Amazon.com ...\n",
       "4        19049      1  good day , , welcome Bank America Earnings Ann...\n",
       "..         ...    ...                                                ...\n",
       "418  141885706      1  good morning , everybody . Chri Schott , pharm...\n",
       "419  141885706      3  okay . good morning , welcome second day Barcl...\n",
       "420  141885706      4  good morning , thank stand . welcome AbbVie Qu...\n",
       "421  141885706      5  good morning , . welcome . go ahead start . Gr...\n",
       "422  141885706      6  hello , welcome , everybody . Jeff Holford , c...\n",
       "\n",
       "[423 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = list(transcript_train1.iloc[:1,2].apply(lambda x: x.noun_chunks))\n",
    "# Modeling bigrams and trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gensim’s simple_preprocess() is great for this. Additionally I have set deacc=True to remove the punctuations.\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "\n",
    "#data_words = list(sent_to_words(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_train1['list_of_words'] = list(sent_to_words(transcript_train1['parsed_componentText_lemma']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>objectId</th>\n",
       "      <th>month</th>\n",
       "      <th>parsed_componentText_lemma</th>\n",
       "      <th>list_of_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>18711</td>\n",
       "      <td>2</td>\n",
       "      <td>good day , lady gentleman , welcome Allstate F...</td>\n",
       "      <td>[good, day, lady, gentleman, welcome, allstate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>18711</td>\n",
       "      <td>5</td>\n",
       "      <td>good day , lady gentleman , welcome Allstate Q...</td>\n",
       "      <td>[good, day, lady, gentleman, welcome, allstate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>18749</td>\n",
       "      <td>2</td>\n",
       "      <td>thank stand . good day , , welcome Amazon.com ...</td>\n",
       "      <td>[thank, stand, good, day, welcome, amazon, com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>18749</td>\n",
       "      <td>4</td>\n",
       "      <td>thank stand . good day , , welcome Amazon.com ...</td>\n",
       "      <td>[thank, stand, good, day, welcome, amazon, com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>19049</td>\n",
       "      <td>1</td>\n",
       "      <td>good day , , welcome Bank America Earnings Ann...</td>\n",
       "      <td>[good, day, welcome, bank, america, earnings, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   objectId  month                         parsed_componentText_lemma  \\\n",
       "0     18711      2  good day , lady gentleman , welcome Allstate F...   \n",
       "1     18711      5  good day , lady gentleman , welcome Allstate Q...   \n",
       "2     18749      2  thank stand . good day , , welcome Amazon.com ...   \n",
       "3     18749      4  thank stand . good day , , welcome Amazon.com ...   \n",
       "4     19049      1  good day , , welcome Bank America Earnings Ann...   \n",
       "\n",
       "                                       list_of_words  \n",
       "0  [good, day, lady, gentleman, welcome, allstate...  \n",
       "1  [good, day, lady, gentleman, welcome, allstate...  \n",
       "2  [thank, stand, good, day, welcome, amazon, com...  \n",
       "3  [thank, stand, good, day, welcome, amazon, com...  \n",
       "4  [good, day, welcome, bank, america, earnings, ...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_train1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "transcript_train1['bigram'] = gensim.models.Phrases(transcript_train1['list_of_words'], min_count=5, threshold=10) # higher threshold fewer phrases.\n",
    "\n",
    "# trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# # Faster way to get a sentence clubbed as a trigram/bigram\n",
    "transcript_train1['bigram_mod'] = transcript_train1['bigram'].apply(lambda x: gensim.models.phrases.Phraser(x))\n",
    "# trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_train1['bigram_text'] = transcript_train1['bigram_mod'].apply(lambda x: x[transcript_train1['list_of_words']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "# transcript_train1['id2word'] = transcript_train1['bigram_text'].apply(lambda x: corpora.Dictionary(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "id2word = corpora.Dictionary(transcript_train1['bigram_text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [id2word.doc2bow(x) for x in transcript_train1['bigram_text'][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "for i in range(len(transcript_train1['bigram_text'][0])):\n",
    "    texts.append(transcript_train1['bigram_text'][0][i])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=25,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how to infer pyLDAvis’s output?\n",
    "\n",
    "Each bubble on the left-hand side plot represents a topic. The larger the bubble, the more prevalent is that topic.\n",
    "\n",
    "A good topic model will have fairly big, non-overlapping bubbles scattered throughout the chart instead of being clustered in one quadrant.\n",
    "\n",
    "A model with too many topics, will typically have many overlaps, small sized bubbles clustered in one region of the chart.\n",
    "\n",
    "Alright, if you move the cursor over one of the bubbles, the words and bars on the right-hand side will update. These words are the salient keywords that form the selected topic.\n",
    "\n",
    "We have successfully built a good looking topic model.\n",
    "\n",
    "Given our prior knowledge of the number of natural topics in the document, finding the best model was fairly straightforward.\n",
    "\n",
    "Upnext, we will improve upon this model by using Mallet’s version of LDA algorithm and then we will focus on how to arrive at the optimal number of topics given any large corpus of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to find the optimal number of topics for LDA?\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=num_topics, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=texts, start=2, limit=30, step=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show graph\n",
    "limit=10; start=2; step=2;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random cut forest to filter out outlier\n",
    "# PCA\n",
    "# classification/regression\n",
    "\n",
    "#visualization\n",
    "# word cloud, feature importance, S&P global leaflet, "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
